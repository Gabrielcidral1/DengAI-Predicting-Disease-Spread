---
title: "DengAI-Predicting-Disease-Spread"
author: "gabriel"
date: "8/7/2019"
output:
  rmdformats::readthedown:
    thumbnails: true
    lightbox: true
    toc_depth: 3
    gallery: true
    highlight: tango
---
---

## loading packages and data

```{r, warning=F}
pacman:: p_load(readr, h2o, dplyr,ggplot2, caret, imputTS, randomForest, prophet, data.table, lubridate, corrplot)

features_tr <- read_csv("dengue_features_train.csv", 
    col_types = cols(week_start_date = col_date(format = "%Y-%m-%d")))

labels_tr <- read_csv("dengue_labels_train.csv")

features_te <- read_csv("dengue_features_test.csv", 
    col_types = cols(week_start_date = col_date(format = "%Y-%m-%d")))

submission_format <- read_csv("submission_format.csv")

```

create two dataset, train and test

```{r, warning=F}

train <- left_join(x = features_tr, y = labels_tr, by = c("year", "weekofyear", "city"))


test <- left_join(x = features_te, y = submission_format, by = c("year", "weekofyear", "city"))

```

### Inital investigation

```{r, warning=F}
#summary(train)

#summary(test)

```

### Checking distributions

the plots below confirm that most of the predictors haves similar distributions across train and test

```{r, warning=F}

train$type <- "train"

test$type <- "test"

all <- rbind(train, test)

for (i in names(all)) {
x <- ggplot(data = all,aes_string(i,color="type")) + geom_density()
print(x)
}
```

### treat NAs


## Split data by city 

```{r, warning=F}

sj <-  train %>% filter(city == "sj") 

ggplot(data = sj, aes(week_start_date, station_precip_mm)) + geom_line()

ggplot(data = sj, aes(x = week_start_date, imputeTS::na.kalman(sj$station_precip_mm))) + geom_line()


```


The missing values will be replaced by a forecast

```{r}

sj <- cbind(sj[ , c("city", "type", "week_start_date")] ,  apply(X = sj[, which(sapply(sj,is.numeric))], MARGIN = 2, function(x) imputeTS::na.kalman(x)))


```



```{r}

iq <- train %>% filter(city == "iq")

ggplot(data = iq, aes(week_start_date, station_diur_temp_rng_c)) + geom_line()

ggplot(data = iq, aes(x = week_start_date, imputeTS::na.kalman(iq$station_diur_temp_rng_c))) + geom_line()


iq <- cbind(iq[ , c("city", "type", "week_start_date")] ,  apply(X = iq[, which(sapply(iq,is.numeric))], MARGIN = 2, function(x) imputeTS::na.kalman(x)))


```

total cases across cities

```{r}
ggplot(sj, aes(week_start_date, y = total_cases)) + geom_line()
ggplot(iq, aes(week_start_date, y = total_cases)) + geom_line()

```

## Correlation analysis (with lags)


### melt data to plot variables against total_cases

```{r}
m <- reshape::melt(data = sj, id.vars = c("city", "type", "week_start_date", "year", "weekofyear")) # create a melted dataframe

ggplot(filter(m, variable %in% c("ndvi_ne", "total_cases")), aes(week_start_date, y = value))+ geom_line() + facet_grid(variable~., scales = "free")

m %>% filter(variable %in% c("station_min_temp_c", "total_cases")) %>%  ggplot(aes(week_start_date, y = value))+ geom_line() + facet_grid(variable~., scales = "free")


```

### Pairwise correlation

### function for pairwise correlation
```{r, warning=F}
pairwiseCor <- function(dataframe){
  pairs <- combn(names(dataframe), 2, simplify=FALSE)
  df <- data.frame(Vairable1=rep(0,length(pairs)), Variable2=rep(0,length(pairs)), 
                   AbsCor=rep(0,length(pairs)), Cor=rep(0,length(pairs)))
  for(i in 1:length(pairs)){
    df[i,1] <- pairs[[i]][1]
    df[i,2] <- pairs[[i]][2]
    df[i,3] <- round(abs(cor(dataframe[,pairs[[i]][1]], dataframe[,pairs[[i]][2]])),4)
    df[i,4] <- round(cor(dataframe[,pairs[[i]][1]], dataframe[,pairs[[i]][2]]),4)
  }
  pairwiseCorDF <- df
  pairwiseCorDF <- pairwiseCorDF[order(pairwiseCorDF$AbsCor, decreasing=TRUE),]
  row.names(pairwiseCorDF) <- 1:length(pairs)
  pairwiseCorDF <<- pairwiseCorDF
  pairwiseCorDF
}
```


```{r, warning=F}


corr_all <- cor(sj[, which(sapply(sj,is.numeric))])

pairwise <- pairwiseCor(sj[, which(sapply(sj,is.numeric))])

pairwise_total_cases <- filter(pairwise, Variable2 == "total_cases")

pairwise_total_cases

findCorrelation(x = corr_all, names = T)

head(pairwise)

```

### Compare correlation by lags

```{r, warning=F}
compare_cor <- c()

for(i in 1:20) {

a <- sj %>% select(station_avg_temp_c,total_cases)  
    
b <- stats::cor(cbind(a$total_cases, lag(a$station_avg_temp_c,i)) , use = "complete.obs")

compare_cor <- rbind(compare_cor, b[1,])

}


which(abs(compare_cor[, 2]) == max(abs(compare_cor[,2])))


```


## split in train and validation 

San Juan
```{r, warning=F}


#sj$total_cases[sj$total_cases > 100] <- 100 # exclude outliers

sj_tr <- head(sj, 657) # train as 70% of the data (not using CreateDataPartition because its time related)

sj_val <- tail(sj, 279) # 30%


```

Iquito

```{r}


#iq$total_cases[iq$total_cases > 30] <- 30

iq_tr <- head(iq, 366)

iq_val <- tail(iq,154)
```

# Modelling San Juan

Get most relevant variables with all data (Var imp)

```{r, warning=F}

sj$city <- NULL


rf_reg <- randomForest(y=sj$total_cases,x=sj[2:23],importance=T,method="rf") # starting in 2 to not use the variable "type"

imp <- as.data.frame(varImp(rf_reg))
imp <- data.frame(overall = imp$Overall,
           names   = rownames(imp))
x <- imp[order(imp$overall,decreasing = T),]

x$names <- as.character(x$names)


imp[order(imp$overall,decreasing = T),]

```
train model 

```{r, warning=F}


sj_tr$city <- NULL

sj_tr$type <- NULL

# Get the best mtry and apply model 

compare <- c()


for(i in c(2:22)) {

rf_reg <- tuneRF(x = sj_tr[ , head(unique(x$names),i)], y = sj_tr$total_cases, ntreeTry=100,stepFactor=2,improve=0.05,trace=F, doBest = T, plot = F) 

pred_sj_val <- predict(rf_reg, sj_val)

res <- postResample(pred_sj_val, sj_val$total_cases)

compare <- cbind(compare ,res)

}


colnames(compare) <- paste("X", c(2:22))

compare <- melt(compare)

ggplot(compare, aes(x = Var2, y = value)) + geom_col() +  facet_grid(Var1~., scales = "free")


```

### Predict in validation

```{r, warning=F}

pred_sj_val <- predict(rf_reg, sj_val)

postResample(pred_sj_val, sj_val$total_cases)

```

train model to predict Test (All train)

```{r, warning=F}

# Exclude irrelevant features 
#sj <- sj[ , -which(names(sj) %in% c("ndvi_nw", "reanalysis_tdtr_k","precipitation_amt_mm" , "reanalysis_sat_precip_amt_mm"	,"ndvi_ne"	,"station_precip_mm"	,"station_diur_temp_rng_c", "ndvi_sw", "ndvi_se", "reanalysis_dew_point_temp_k", "city", "type"))]

# apply lag to certain features

sj$reanalysis_specific_humidity_g_per_kg <- lag(sj$reanalysis_specific_humidity_g_per_kg, 8) 
sj$station_avg_temp_c <- lag(sj$station_avg_temp_c, 10)


# Get the best mtry train a random forest using that mtry

sj <- sj[11:936 , 2:25] # to exclude NAs

rf_reg <- tuneRF(x = sj[,1:13], sj$total_cases, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, doBest = T) 


```

### Make final prediction for San Juan (test)

```{r, warning=F}

sj_te <- test %>% filter(city == "sj")

```

The missing values will be replaced by a forecast

```{r, warning=F}

sj_te <- cbind(sj_te[ , c("city", "type", "week_start_date")] ,  apply(X = sj_te[, which(sapply(sj_te,is.numeric))], MARGIN = 2, function(x) imputeTS::na.kalman(x)))

```

### Predict

```{r, warning=F}

sj_te$total_cases <- predict(rf_reg , sj_te)


```

# Modelling Iquito

Get most relevant variables (Var imp)

```{r, warning=F}

iq_tr$city <- NULL

rf_reg<-randomForest(y=iq$total_cases,x=iq[3:23],importance=T,method="rf")

imp <- as.data.frame(varImp(rf_reg))
imp <- data.frame(overall = imp$Overall,
           names   = rownames(imp))
x <- imp[order(imp$overall,decreasing = T),]

x$names <- as.character(x$names)

```
train model 

```{r, warning=F}

# Get the best mtry
rf_reg <- tuneRF(iq_tr[ , head(unique(x$names),15)], iq_tr$total_cases, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, doBest = T) 


```

predict in validation

```{r, warning=F}

pred_iq_val <- predict(object = rf_reg, iq_val)

postResample(pred_iq_val, iq_val$total_cases)


```

train model to predict Test (All train)

```{r, warning=F}

# Get the best mtry
rf_reg<-tuneRF(iq[ , head(unique(x$names),15)], iq$total_cases, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, doBest = T) 


```

### Make final prediction for Iquito (test)

```{r}

iq_te <- test %>% filter(city == "iq")

```

The missing values will be replaced by a forecast

```{r, warning=F}

iq_te <- cbind(iq_te[ , c("city", "type", "week_start_date")] ,  apply(X = iq_te[, which(sapply(iq_te,is.numeric))], MARGIN = 2, function(x) imputeTS::na.kalman(x)))


```

```{r, warning=F}

iq_te$total_cases <- predict(rf_reg, iq_te)

```

# Final Submission using RF

```{r, warning=F}
names(iq_te)

rf_final_df <- rbind(iq_te, sj_te)

submission_format$total_cases <- NULL

submission_rf <- left_join(submission_format, y = rf_final_df, by = c("year","weekofyear", "city"))

submission_rf <- submission_rf %>% select(city, year, weekofyear, total_cases)

submission_rf$total_cases <- base::round(submission_rf$total_cases,0)

write.csv(submission_rf, "submission_rf.csv", quote = F, row.names = F)

```

# Prophet

## Prophet San Juan


```{r, warning=F}

sj_prophet <- setnames(sj, c("week_start_date", "total_cases"),new = c("ds","y"))

sj_prohet_model <- prophet(sj_prophet)

future <- make_future_dataframe(sj_prohet_model, 500, freq = "week")

forecast <- predict(sj_prohet_model, future)

forecast$year <- year(forecast$ds)

forecast$weekofyear <- week(forecast$ds)


dyplot.prophet(x = sj_prohet_model, fcst = forecast)

```

### Match Prophet and submission

```{r, warning=F}


forecast$ds <- as.Date(forecast$ds)

forecast$city <- "sj"

forecast_sj <- forecast

submission <- left_join(submission_format, y = forecast[ , c("ds","weekofyear","year", "yhat", "city")], by = c("year","weekofyear", "city"))


```

# Prophet Iquito



```{r, warning=F}

iq_prophet <- setnames(iq, c("week_start_date", "total_cases"),new = c("ds","y"))

iq_prohet_model <- prophet(iq_prophet)

future <- make_future_dataframe(iq_prohet_model, 500, freq = "week")

forecast <- predict(iq_prohet_model, future)

forecast$year <- year(forecast$ds)

forecast$weekofyear <- week(forecast$ds)


dyplot.prophet(x = iq_prohet_model, fcst = forecast)

```

### Match Prophet and submission

```{r, warning=F}


forecast$ds <- as.Date(forecast$ds)

forecast$city <- "iq"

forecast <- rbind(forecast_sj, forecast)

submission <- left_join(submission_format, y = forecast[ , c("ds","weekofyear","year", "yhat", "city")], by = c("year","weekofyear", "city"))

submission$yhat <- imputeTS::na.kalman(submission$yhat) # fill NAs due to 53 week year


```

### Change negative values to 0

```{r, warning=F}

submission$yhat[submission$yhat < 0 ] <- 0

submission$total_cases <- submission$yhat

submission <- submission %>% select(city, year, weekofyear, total_cases)

submission$total_cases <- base::round(submission$total_cases,0)

write.csv(submission, "submission.csv", quote = F, row.names = F)



```


## Final final submission with the mean of both previous

```{r, warning=F}

submission_mean <- submission 

a <- cbind(submission$total_cases, submission_rf$total_cases)

submission_mean$total_cases <- round(apply(X = a, MARGIN = 1, function(x) mean(x)),0)

write.csv(submission_mean, "submission_mean.csv", quote = F, row.names = F)

  
```

