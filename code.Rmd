---
title: "DengAI-Predicting-Disease-Spread"
author: "gabriel"
date: "8/7/2019"
output:
  rmdformats::readthedown:
    thumbnails: true
    lightbox: true
    toc_depth: 3
    gallery: true
    highlight: tango
---
---

## loading packages and data

```{r, warning=F, message=F}
pacman:: p_load(readr, h2o, dplyr,ggplot2, caret, imputTS, randomForest, prophet, data.table, lubridate, corrplot)

features_tr <- read_csv("dengue_features_train.csv", 
    col_types = cols(week_start_date = col_date(format = "%Y-%m-%d")))

labels_tr <- read_csv("dengue_labels_train.csv")

features_te <- read_csv("dengue_features_test.csv", 
    col_types = cols(week_start_date = col_date(format = "%Y-%m-%d")))

submission_format <- read_csv("submission_format.csv")


options(scipen=999)



```

create two dataset, train and test

```{r, warning=F}

train <- left_join(x = features_tr, y = labels_tr, by = c("year", "weekofyear", "city"))


test <- left_join(x = features_te, y = submission_format, by = c("year", "weekofyear", "city"))

```

### Inital investigation

```{r, warning=F}
#summary(train)

#summary(test)

```

### Checking distributions

the plots below confirm that most of the predictors haves similar distributions across train and test

```{r, warning=F}

train$type <- "train"

test$type <- "test"


summary(all[ , c("station_avg_temp_c", "reanalysis_avg_temp_k", "reanalysis_air_temp_k")])

summary(all[ , c("station_precip_mm", "precipitation_amt_mm")])

all %>% group_by(city,year, week_start_date) %>%  mutate(avg_temp = mean(reanalysis_avg_temp_k, reanalysis_air_temp_k, na.rm = T, trim = 0), avg_precip = mean(station_precip_mm, precipitation_amt_mm, na.rm = T, trim = 0),  station_avg_temp_c = NULL, reanalysis_avg_temp_k = NULL, reanalysis_air_temp_k = NULL, station_precip_mm = NULL, precipitation_amt_mm = NULL) # Create avg of tempearature and preciptation

all <- rbind(train, test)

for (i in names(all)) {
x <- ggplot(data = all,aes_string(i,color="type")) + geom_density()
print(x)
}
```

### treat NAs


## Split data by city 

```{r, warning=F}

sj <-  train %>% filter(city == "sj") 


ggplot(data = sj, aes(week_start_date, station_precip_mm)) + geom_line()

ggplot(data = sj, aes(x = week_start_date, imputeTS::na.kalman(sj$station_precip_mm))) + geom_line()


```


The missing values will be replaced by a forecast

```{r}

sj <- cbind(sj[ , c("city", "type", "week_start_date")] ,  apply(X = sj[, which(sapply(sj,is.numeric))], MARGIN = 2, function(x) imputeTS::na.kalman(x)))


```



```{r}

iq <- train %>% filter(city == "iq")

ggplot(data = iq, aes(week_start_date, station_diur_temp_rng_c)) + geom_line()

ggplot(data = iq, aes(x = week_start_date, imputeTS::na.kalman(iq$station_diur_temp_rng_c))) + geom_line()


iq <- cbind(iq[ , c("city", "type", "week_start_date")] ,  apply(X = iq[, which(sapply(iq,is.numeric))], MARGIN = 2, function(x) imputeTS::na.kalman(x)))


```

total cases across cities

```{r}
ggplot(sj, aes(week_start_date, y = total_cases)) + geom_line()
ggplot(iq, aes(week_start_date, y = total_cases)) + geom_line()

```

## Correlation analysis (with lags)


### melt data to plot variables against total_cases

```{r}
m <- reshape::melt(data = sj, id.vars = c("city", "type", "week_start_date", "year", "weekofyear")) # create a melted dataframe

ggplot(filter(m, variable %in% c("ndvi_ne", "total_cases")), aes(week_start_date, y = value))+ geom_line() + facet_grid(variable~., scales = "free")

m %>% filter(variable %in% c("station_min_temp_c", "total_cases")) %>%  ggplot(aes(week_start_date, y = value))+ geom_line() + facet_grid(variable~., scales = "free")


```

### Pairwise correlation

### function for pairwise correlation
```{r, warning=F}
pairwiseCor <- function(dataframe){
  pairs <- combn(names(dataframe), 2, simplify=FALSE)
  df <- data.frame(Vairable1=rep(0,length(pairs)), Variable2=rep(0,length(pairs)), 
                   AbsCor=rep(0,length(pairs)), Cor=rep(0,length(pairs)))
  for(i in 1:length(pairs)){
    df[i,1] <- pairs[[i]][1]
    df[i,2] <- pairs[[i]][2]
    df[i,3] <- round(abs(cor(dataframe[,pairs[[i]][1]], dataframe[,pairs[[i]][2]])),4)
    df[i,4] <- round(cor(dataframe[,pairs[[i]][1]], dataframe[,pairs[[i]][2]]),4)
  }
  pairwiseCorDF <- df
  pairwiseCorDF <- pairwiseCorDF[order(pairwiseCorDF$AbsCor, decreasing=TRUE),]
  row.names(pairwiseCorDF) <- 1:length(pairs)
  pairwiseCorDF <<- pairwiseCorDF
  pairwiseCorDF
}
```


```{r, warning=F}

training_size <- createDataPartition(sj$total_cases, p = 0.7, list = F)  

pairwise <- pairwiseCor(sj[, which(sapply(sj,is.numeric))])

pairwise_total_cases <- filter(pairwise, Variable2 == "total_cases")

pairwise_total_cases

#findCorrelation(x = corr_all, names = T)

head(pairwise)

```

### Compare correlation by lags

```{r, warning=F}
compare_cor <- c()

for(i in 1:20) {

a <- sj %>% select(station_avg_temp_c,total_cases)  
    
b <- stats::cor(cbind(a$total_cases, lag(a$station_avg_temp_c,i)), method = "spearman" , use = "complete.obs")

compare_cor <- rbind(compare_cor, b[1,])

}


# sj <- sj %>% mutate(total_cases = lead(total_cases, 1), week_start_date = lead(week_start_date, 1) , weekofyear = lead(weekofyear, 1), year = lead(year, 1))

sj <- sj[-which(is.na(sj$total_cases)) , ] # Exclude NA generated by lead 

corrplot(cor(x = sj[, which(sapply(sj,is.numeric))], method = "spearman"))

```



# Modelling San Juan

Get most relevant variables with all data (Var imp)

```{r, warning=F}

sj$city <- NULL

preprocessparams <- preProcess(x = sj[-which(colnames(sj_tr)=="total_cases")],method = c("center","scale","pca","BoxCox"))

```
train model to predict Test (All train)

```{r, warning=F, message=F}


sj <- predict(preprocessparams, sj)

rf_reg <- tuneRF(x = sj[ , -which(names(sj) == "total_cases")], sj$total_cases, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, doBest = T) 


```

### Make final prediction for San Juan (test)

```{r, warning=F}

sj_te <- test %>% filter(city == "sj")

```

The missing values will be replaced by a forecast

```{r, warning=F}

sj_te <- cbind(sj_te[ , c("city", "type", "week_start_date")] ,  apply(X = sj_te[, which(sapply(sj_te,is.numeric))], MARGIN = 2, function(x) imputeTS::na.kalman(x)))

```

### Predict

```{r, warning=F}

sj_te$total_cases <- predict(rf_reg , sj_te)


```

# Modelling Iquito

Iquito

Get most relevant variables (Var imp)

```{r, warning=F}

iq_tr$city <- NULL

```

train model 

```{r, warning=F}

# Get the best mtry
rf_reg <- tuneRF(iq_tr[ , head(unique(x$names),15)], iq_tr$total_cases, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, doBest = T) 


```


train model to predict Test (All train)

```{r, warning=F}

# Get the best mtry
rf_reg <- tuneRF( x = iq[ , -which(names(iq) == "total_cases")], y = iq$total_cases, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, doBest = T) 


```

### Make final prediction for Iquito (test)

```{r}

iq_te <- test %>% filter(city == "iq")

```

The missing values will be replaced by a forecast

```{r, warning=F}

iq_te <- cbind(iq_te[ , c("city", "type", "week_start_date")] ,  apply(X = iq_te[, which(sapply(iq_te,is.numeric))], MARGIN = 2, function(x) imputeTS::na.kalman(x)))


```

```{r, warning=F}

iq_te$total_cases <- predict(rf_reg, iq_te)

```

# Final Submission using RF

```{r, warning=F}

rf_final_df <- rbind(iq_te, sj_te)

submission_format$total_cases <- NULL

submission_rf <- left_join(submission_format, y = rf_final_df, by = c("year","weekofyear", "city"))

submission_rf <- submission_rf %>% select(city, year, weekofyear, total_cases)

# match 


submission_rf$total_cases <- base::round(submission_rf$total_cases,0)

write.csv(submission_rf, "submission_rf.csv", quote = F, row.names = F)

```

# Prophet

## Prophet San Juan


```{r, warning=F}

sj_prophet <- setnames(sj, c("week_start_date", "total_cases"),new = c("ds","y"))

sj_prohet_model <- prophet(sj_prophet)

future <- make_future_dataframe(sj_prohet_model, 500, freq = "week")

forecast <- predict(sj_prohet_model, future)

forecast$year <- year(forecast$ds)

forecast$weekofyear <- week(forecast$ds)


dyplot.prophet(x = sj_prohet_model, fcst = forecast)

```

### Match Prophet and submission

```{r, warning=F}


forecast$ds <- as.Date(forecast$ds)

forecast$city <- "sj"

forecast_sj <- forecast

submission <- left_join(submission_format, y = forecast[ , c("ds","weekofyear","year", "yhat", "city")], by = c("year","weekofyear", "city"))


```

# Prophet Iquito



```{r, warning=F}

iq_prophet <- setnames(iq, c("week_start_date", "total_cases"),new = c("ds","y"))

iq_prohet_model <- prophet(iq_prophet)

future <- make_future_dataframe(iq_prohet_model, 500, freq = "week")

forecast <- predict(iq_prohet_model, future)

forecast$year <- year(forecast$ds)

forecast$weekofyear <- week(forecast$ds)


dyplot.prophet(x = iq_prohet_model, fcst = forecast)

```

### Match Prophet and submission

```{r, warning=F}


forecast$ds <- as.Date(forecast$ds)

forecast$city <- "iq"

forecast <- rbind(forecast_sj, forecast)

submission <- left_join(submission_format, y = forecast[ , c("ds","weekofyear","year", "yhat", "city")], by = c("year","weekofyear", "city"))

submission$yhat <- imputeTS::na.kalman(submission$yhat) # fill NAs due to 53 week year


```

### Change negative values to 0

```{r, warning=F}

submission$yhat[submission$yhat < 0 ] <- 0

submission$total_cases <- submission$yhat

submission <- submission %>% select(city, year, weekofyear, total_cases)

submission$total_cases <- base::round(submission$total_cases,0)

write.csv(submission, "submission.csv", quote = F, row.names = F)



```


## Final final submission with the mean of both previous

```{r, warning=F}

submission_mean <- submission 

a <- cbind(submission$total_cases, submission_rf$total_cases)

submission_mean$total_cases <- round(apply(X = a, MARGIN = 1, function(x) mean(x)),0)

write.csv(submission_mean, "submission_mean.csv", quote = F, row.names = F)

  
```

<!-- begin wwww.htmlcommentbox.com -->
<div id="HCB_comment_box"><a href="http://www.htmlcommentbox.com">Comment Box</a> is loading comments...</div>
<link rel="stylesheet" type="text/css" href="https://www.htmlcommentbox.com/static/skins/bootstrap/twitter-bootstrap.css?v=0" />
<script type="text/javascript" id="hcb"> /*<!--*/ if(!window.hcb_user){hcb_user={};} (function(){var s=document.createElement("script"), l=hcb_user.PAGE || (""+window.location).replace(/'/g,"%27"), h="https://www.htmlcommentbox.com";s.setAttribute("type","text/javascript");s.setAttribute("src", h+"/jread?page="+encodeURIComponent(l).replace("+","%2B")+"&mod=%241%24wq1rdBcg%24QU9x23GQcVLZySCO.uLVx."+"&opts=16862&num=10&ts=1563265318041");if (typeof s!="undefined") document.getElementsByTagName("head")[0].appendChild(s);})(); /*-->*/ </script>
<!-- end www.htmlcommentbox.com -->