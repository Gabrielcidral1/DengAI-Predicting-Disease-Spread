---
title: "DengAI-Predicting-Disease-Spread"
author: "gabriel"
date: "8/7/2019"
output:
  rmdformats::readthedown:
    thumbnails: true
    lightbox: true
    toc_depth: 3
    gallery: true
    highlight: tango
---
---

## loading packages and data

```{r, warning=F, message=F}
pacman:: p_load(readr, h2o, dplyr,ggplot2, caret, imputTS, randomForest, prophet, data.table, lubridate, corrplot, quantreg, iClick)

features_tr <- read_csv("./input/dengue_features_train.csv", 
    col_types = cols(week_start_date = col_date(format = "%Y-%m-%d")))

labels_tr <- read_csv("./input/dengue_labels_train.csv")

features_te <- read_csv("./input/dengue_features_test.csv", 
    col_types = cols(week_start_date = col_date(format = "%Y-%m-%d")))

submission_format <- read_csv("./input/submission_format.csv")

options(scipen=999)


```

create two dataset, train and test

```{r, warning=F}

train <- left_join(x = features_tr, y = labels_tr, by = c("year", "weekofyear", "city"))

test <- left_join(x = features_te, y = submission_format, by = c("year", "weekofyear", "city"))

train$type <- "train"

test$type <- "test"

all <- rbind(train, test)

summary(all[ , c("station_avg_temp_c", "reanalysis_avg_temp_k", "reanalysis_air_temp_k")])

summary(all[ , c("station_precip_mm", "precipitation_amt_mm")])

all %>% group_by(city,year, week_start_date) %>%  mutate(avg_temp = mean(reanalysis_avg_temp_k, reanalysis_air_temp_k, na.rm = T, trim = 0), avg_precip = mean(station_precip_mm, precipitation_amt_mm, na.rm = T, trim = 0),  station_avg_temp_c = NULL, reanalysis_avg_temp_k = NULL, reanalysis_air_temp_k = NULL, station_precip_mm = NULL, precipitation_amt_mm = NULL) # Create avg of tempearature and preciptation


```

### Inital investigation

```{r, warning=F}
#summary(train)

#summary(test)

```

### Checking distributions

the plots below confirm that most of the predictors haves similar distributions across train and test

```{r, warning=F}

train$type <- "train"

test$type <- "test"

all <- rbind(train, test)

for (i in names(all)) {
x <- ggplot(data = all,aes_string(i,color="type")) + geom_density()
print(x)
}
```

### treat NAs


## Split data by city 

```{r, warning=F}

sj <-  all %>% filter(city == "sj" | type == "train") 


ggplot(data = sj, aes(week_start_date, station_precip_mm)) + geom_line()

ggplot(data = sj, aes(x = week_start_date, imputeTS::na.kalman(sj$station_precip_mm))) + geom_line()


```


The missing values will be replaced by a forecast

```{r}

sj <- cbind(sj[ , c("city", "type", "week_start_date")] ,  apply(X = sj[, which(sapply(sj,is.numeric))], MARGIN = 2, function(x) imputeTS::na.kalman(x)))

write.csv(sj, "sj.csv")

```

Iquitos

```{r}

iq <- all %>% filter(city == "iq" | type == "train")

ggplot(data = iq, aes(week_start_date, station_diur_temp_rng_c)) + geom_line()

ggplot(data = iq, aes(x = week_start_date, imputeTS::na.kalman(iq$station_diur_temp_rng_c))) + geom_line()


iq <- cbind(iq[ , c("city", "type", "week_start_date")] ,  apply(X = iq[, which(sapply(iq,is.numeric))], MARGIN = 2, function(x) imputeTS::na.kalman(x)))

write.csv(iq, "iq.csv")
```

total cases across cities

```{r}
ggplot(sj, aes(week_start_date, y = total_cases)) + geom_line()
ggplot(iq, aes(week_start_date, y = total_cases)) + geom_line()

```

## Correlation analysis (with lags)


### melt data to plot variables against total_cases

```{r}
m <- reshape::melt(data = sj, id.vars = c("city", "type", "week_start_date", "year", "weekofyear")) # create a melted dataframe

ggplot(filter(m, variable %in% c("ndvi_ne", "total_cases")), aes(week_start_date, y = value))+ geom_line() + facet_grid(variable~., scales = "free")

m %>% filter(variable %in% c("station_min_temp_c", "total_cases")) %>%  ggplot(aes(week_start_date, y = value))+ geom_line() + facet_grid(variable~., scales = "free")


```

### Pairwise correlation

### function for pairwise correlation
```{r, warning=F}
pairwiseCor <- function(dataframe){
  pairs <- combn(names(dataframe), 2, simplify=FALSE)
  df <- data.frame(Vairable1=rep(0,length(pairs)), Variable2=rep(0,length(pairs)), 
                   AbsCor=rep(0,length(pairs)), Cor=rep(0,length(pairs)))
  for(i in 1:length(pairs)){
    df[i,1] <- pairs[[i]][1]
    df[i,2] <- pairs[[i]][2]
    df[i,3] <- round(abs(cor(dataframe[,pairs[[i]][1]], dataframe[,pairs[[i]][2]], method = "spearman")),4)
    df[i,4] <- round(cor(dataframe[,pairs[[i]][1]], dataframe[,pairs[[i]][2]], method = "spearman"),4)
  }
  pairwiseCorDF <- df
  pairwiseCorDF <- pairwiseCorDF[order(pairwiseCorDF$AbsCor, decreasing=TRUE),]
  row.names(pairwiseCorDF) <- 1:length(pairs)
  pairwiseCorDF <<- pairwiseCorDF
  pairwiseCorDF
}


```


```{r, warning=F}


corr_all <- cor(sj[, which(sapply(sj,is.numeric))])

pairwise <- pairwiseCor(sj[, which(sapply(sj,is.numeric))])

pairwise_total_cases <- filter(pairwise, Variable2 == "total_cases")

pairwise_total_cases

findCorrelation(x = corr_all, names = T)

head(pairwise)

```

### Compare correlation by lags

```{r, warning=F}
compare_cor <- c()

for(i in 1:20) {

a <- sj %>% select(station_avg_temp_c,total_cases)  
    
b <- stats::cor(cbind(a$total_cases, lag(a$station_avg_temp_c,i)), method = "spearman" , use = "complete.obs")

compare_cor <- rbind(compare_cor, b[1,])

}

which(abs(compare_cor[, 2]) == max(abs(compare_cor[,2])))


sj <- sj %>% mutate(total_cases = lead(total_cases, 1), week_start_date = lead(week_start_date, 1) , weekofyear = lead(weekofyear, 1), year = lead(year, 1))

sj <- sj[-which(is.na(sj$total_cases)) , ] # Exclude NA generated by lead 

#corrplot(cor(x = sj[, which(sapply(sj,is.numeric))], method = "spearman"))

```


# Modelling San Juan

Get most relevant variables with all data (Var imp)

```{r, warning=F}

sj$city <- NULL

rf_reg <- randomForest(y=sj$total_cases,x=sj[, 2:23],importance=T,method="rf") # starting in 2 to not use the variable "type"


imp <- as.data.frame(varImp(rf_reg))
imp <- data.frame(overall = imp$Overall,
           names   = rownames(imp))
x <- imp[order(imp$overall,decreasing = T),]

x$names <- as.character(x$names)


imp[order(imp$overall,decreasing = T),]

```
train model 

```{r, warning=F}
sj_tr$city <- NULL
# sj_tr$week_start_date <- NULL
sj_tr$type <- NULL

sj_val$city <- NULL
sj_val$type <- NULL
sj_val$week_start_date <- NULL

# Get the best mtry and apply model 

# compare <- c()
# 
# b <- c(13:ncol(sj_tr)) # change this number to select different number of variables to try

# for(i in b) {
# 
# rf_reg <- randomForest::tuneRF(x = sj_tr[ , head(unique(x$names),i)], y = sj_tr$total_cases, ntreeTry=100,stepFactor=2,improve=0.05,trace=F, doBest = T, plot = F) 
# 
#   
# pred_sj_val <- predict(rf_reg, sj_val)
# 
# res <- postResample(pred_sj_val, sj_val$total_cases)
# 
# compare <- cbind(compare ,res)
# 
# }


#colnames(compare) <- paste("X", b)

#compare <- melt(compare)

#ggplot(compare, aes(x = Var2, y = value)) + geom_col() +  facet_grid(Var1~., scales = "free")
```


```{r, warning=F}

preprocessparams <- preProcess(x = sj_tr[-which(colnames(sj_tr)=="total_cases")],method = c("center","scale","pca","BoxCox"))



sj_tr <- predict(preprocessparams,sj_tr)

rf_reg <- randomForest::tuneRF(y = sj_tr$total_cases, x = sj_tr[ , -which(colnames(sj_tr) %in% c("total_cases", "week_start_date"))], ntreeTry=100,stepFactor=2,improve=0.05,trace=F, doBest = T, plot = F) 

# rf_reg <- quantreg::rq(formula = total_cases~., data = sj[ , -c(1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,14)], tau = .5)
# 
# rf_reg <- knnreg(y = sj$total_cases , x = as.data.frame(sj$reanalysis_specific_humidity_g_per_kg))
# 

sj_tr$bb <- predict(rf_reg , data = sj_tr)

#postResample(pred = bb, sj$total_cases)

ggplot(data = sj_tr, aes(x = week_start_date)) + geom_line(aes(y = total_cases, color = "real")) + geom_line(aes(y = (bb), color = "pred" )) 


ggplot(data = sj, aes(x = week_start_date)) + geom_line(aes(y = total_cases, color = "real")) # + geom_line(aes(y = (bb), color = "pred" )) 


sj_tr$bb <- NULL

ggplot(data = sj, aes(x = weekofyear)) + geom_line(aes(y = total_cases, color = "real")) + geom_line(aes(y = (reanalysis_specific_humidity_g_per_kg^2), color = "pred" )) 



# rf_reg <- knnreg(y = sj_tr$total_cases, x = sj_tr[ , -which(colnames(sj_tr)=="total_cases")])

```

### Predict in validation

```{r, warning=F}

#sj_val$week_start_date <- NULL

sj_val_pca <- predict(preprocessparams,sj_val)

summary(sj_val_pca)

sj_val_pca <- cbind(sj_val_pca, sj_val$weekofyear)

sj_val_pca <- sj_val_pca[complete.cases(sj_val_pca) , ]

names(sj_val_pca)[13] <- "weekofyear"

sj_val_pca$pred <- predict(rf_reg, sj_val_pca)

#pred_sj_val <- as.vector(pred_sj_val)

#n <- as.data.frame(cbind(pred_sj_val, sj_val$total_cases))

postResample(sj_val_pca$total_cases, sj_val_pca$pred)

ggplot(data = sj_val_pca, aes(x = weekofyear)) + geom_line(aes(y = total_cases, color = "real")) #+ geom_line(aes(y = pred, color = "pred" )) 

```

train model to predict Test (All train)

```{r, warning=F, message=F, echo=T}

# Exclude irrelevant features 
#sj <- sj[ , -which(names(sj) %in% c("ndvi_nw", "reanalysis_tdtr_k","precipitation_amt_mm" , "reanalysis_sat_precip_amt_mm"	,"ndvi_ne"	,"station_precip_mm"	,"station_diur_temp_rng_c", "ndvi_sw", "ndvi_se", "reanalysis_dew_point_temp_k", "city", "type"))]

# apply lag to certain features

#sj$reanalysis_specific_humidity_g_per_kg <- lag(sj$reanalysis_specific_humidity_g_per_kg, 8) 
#sj$station_avg_temp_c <- lag(sj$station_avg_temp_c, 10)


# Get the best mtry train a random forest using that mtry

preprocessparams <- preProcess(x = sj[-which(colnames(sj)=="total_cases")],method = c("center","scale","pca","BoxCox"))

sj <- predict(preprocessparams, sj)

sj$type <- NULL
#sj$week_start_date <- NULL

rf_reg <- tuneRF(x = sj[ , -which(names(sj) == "total_cases")], y = sj$total_cases, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, doBest = T) 

sj$pred <- predict(rf_reg, sj)

postResample(sj$pred, sj$total_cases)

ggplot(data = sj, aes(x = week_start_date)) + geom_line(aes(y = total_cases, color = "real")) + geom_line(aes(y = pred, color = "pred" )) 

```

### Make final prediction for San Juan (test)

```{r, warning=F}

sj_te <- all %>% filter(city == "sj" | type == "test")

```

The missing values will be replaced by a forecast

```{r, warning=F}

sj_te <- cbind(sj_te[ , c("city", "type", "week_start_date")] ,  apply(X = sj_te[, which(sapply(sj_te,is.numeric))], MARGIN = 2, function(x) imputeTS::na.kalman(x)))

```

### Apply parameters and predict

```{r, warning=F}

sj_te <- predict(preprocessparams, sj_te)

sj_te$total_cases <- predict(rf_reg , sj_te)



```

# Modelling Iquito

Iquito

```{r}


#iq$total_cases[iq$total_cases > 30] <- 30

iq_tr <- head(iq, 366)

iq_val <- tail(iq,154)
```



Get most relevant variables (Var imp)

```{r, warning=F}

iq_tr$city <- NULL

rf_reg <- randomForest(y=iq$total_cases,x=iq[3:23],importance=T,method="rf")

imp <- as.data.frame(varImp(rf_reg))
imp <- data.frame(overall = imp$Overall,
           names   = rownames(imp))
x <- imp[order(imp$overall,decreasing = T),]

x$names <- as.character(x$names)

```

train model 

```{r, warning=F, results=F}

# Get the best mtry
rf_reg <- tuneRF(iq_tr[ , head(unique(x$names),15)], iq_tr$total_cases, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, doBest = T) 


```

predict in validation

```{r, warning=F}

pred_iq_val <- predict(object = rf_reg, iq_val)

postResample(pred_iq_val, iq_val$total_cases)


```

train model to predict Test (All train)

```{r, warning=F}


iq$city <- NULL

iq$type <- NULL

iq$year <- NULL

iq$weekofyear <- NULL

# Get the best mtry

preprocessparams <- preProcess(x = iq[ , -which(colnames(iq)=="total_cases")],method = c("center","scale","pca","BoxCox"))

iq <- predict(preprocessparams, iq)



rf_reg <- tuneRF(iq, iq$total_cases, ntreeTry=100,stepFactor=2,improve=0.05,trace=TRUE, doBest = T) 


```

### Make final prediction for Iquito (test)

```{r}

iq_te <- all %>% filter(city == "iq" | type == "test")


```

The missing values will be replaced by a forecast

```{r, warning=F}

iq_te <- cbind(iq_te[ , c("city", "type", "week_start_date")] ,  apply(X = iq_te[, which(sapply(iq_te,is.numeric))], MARGIN = 2, function(x) imputeTS::na.kalman(x)))


```


```{r}
iq_te$type <- NULL
iq_te$city <- NULL
iq_te$year <- NULL
#iq_te$weekofyear <- NULL
#iq_te$week_start_date <- NULL

preprocessparams <- preProcess(x = iq_te[-which(colnames(iq_te)=="total_cases")],method = c("center","scale","pca", "BoxCox"))

iq_te <- predict(preprocessparams, iq_te)

```


```{r, warning=F}

iq_te$total_cases <- predict(rf_reg, iq_te)


```

# Final Submission using RF

```{r, warning=F}


names(sj_te) %in% names(iq_te)

names(iq_te)

iq_te$city <- "iq" 

iq_te$type <- "test"



names(sj_te)



rf_final_df <- rbind(iq_te, sj_te)

submission_format$total_cases <- NULL

submission_rf <- left_join(submission_format, y = rf_final_df, by = c("year","weekofyear", "city"))

submission_rf <- submission_rf %>% select(city, year, weekofyear, total_cases)

# match 


submission_rf$total_cases <- base::round(submission_rf$total_cases,0)

write.csv(submission_rf, "submission_rf.csv", quote = F, row.names = F)

```

# Prophet

## Prophet San Juan

```{r, warning=F}

sj_prophet <- setnames(sj, c("week_start_date", "total_cases"),new = c("ds","y"))

sj_prohet_model <- prophet(sj_prophet)

future <- make_future_dataframe(sj_prohet_model, 500, freq = "week")

forecast <- predict(sj_prohet_model, future)

forecast$year <- year(forecast$ds)

forecast$weekofyear <- week(forecast$ds)


dyplot.prophet(x = sj_prohet_model, fcst = forecast)

```

### Match Prophet and submission

```{r, warning=F}


forecast$ds <- as.Date(forecast$ds)

forecast$city <- "sj"

forecast_sj <- forecast

submission <- left_join(submission_format, y = forecast[ , c("ds","weekofyear","year", "yhat", "city")], by = c("year","weekofyear", "city"))


```

# Prophet Iquito



```{r, warning=F}

iq_prophet <- setnames(iq, c("week_start_date", "total_cases"),new = c("ds","y"))

iq_prohet_model <- prophet(iq_prophet)

future <- make_future_dataframe(iq_prohet_model, 500, freq = "week")

forecast <- predict(iq_prohet_model, future)

forecast$year <- year(forecast$ds)

forecast$weekofyear <- week(forecast$ds)

dyplot.prophet(x = iq_prohet_model, fcst = forecast)

```

### Match Prophet and submission

```{r, warning=F}


forecast$ds <- as.Date(forecast$ds)

forecast$city <- "iq"

forecast <- rbind(forecast_sj, forecast)

submission <- left_join(submission_format, y = forecast[ , c("ds","weekofyear","year", "yhat", "city")], by = c("year","weekofyear", "city"))

submission$yhat <- imputeTS::na.kalman(submission$yhat) # fill NAs due to 53 week year


```

### Change negative values to 0

```{r, warning=F}

submission$yhat[submission$yhat < 0 ] <- 0

submission$total_cases <- submission$yhat

submission <- submission %>% select(city, year, weekofyear, total_cases)

submission$total_cases <- base::round(submission$total_cases,0)

write.csv(submission, "submission.csv", quote = F, row.names = F)



```


## Final final submission with the mean of both previous

```{r, warning=F}

submission_mean <- submission 

a <- cbind(submission$total_cases, submission_rf$total_cases)

submission_mean$total_cases <- round(apply(X = a, MARGIN = 1, function(x) mean(x)),0)

write.csv(submission_mean, "submission_mean.csv", quote = F, row.names = F)

  
```

<!-- begin wwww.htmlcommentbox.com -->
<div id="HCB_comment_box"><a href="http://www.htmlcommentbox.com">Comment Box</a> is loading comments...</div>
<link rel="stylesheet" type="text/css" href="https://www.htmlcommentbox.com/static/skins/bootstrap/twitter-bootstrap.css?v=0" />
<script type="text/javascript" id="hcb"> /*<!--*/ if(!window.hcb_user){hcb_user={};} (function(){var s=document.createElement("script"), l=hcb_user.PAGE || (""+window.location).replace(/'/g,"%27"), h="https://www.htmlcommentbox.com";s.setAttribute("type","text/javascript");s.setAttribute("src", h+"/jread?page="+encodeURIComponent(l).replace("+","%2B")+"&mod=%241%24wq1rdBcg%24QU9x23GQcVLZySCO.uLVx."+"&opts=16862&num=10&ts=1563265318041");if (typeof s!="undefined") document.getElementsByTagName("head")[0].appendChild(s);})(); /*-->*/ </script>
<!-- end www.htmlcommentbox.com -->